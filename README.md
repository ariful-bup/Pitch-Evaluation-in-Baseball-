# Pitch-Evaluation-in-Baseball-
Fusing Vision and Biomechanics for Accurate Pitch Evaluation in Baseball Using Deep Learning Techniques.

This study presents an advanced deep learning-based system that detects, tracks, and evaluates baseball pitches by analyzing video sequences from professional broadcast and amateur pitching sessions. It is able to detect small, high-speed baseballs in every frame of high-frame-rate video using the YOLO12 object detection framework, ensuring accurate tracking from the moment the ball is thrown from the pitcher's hand to the moment it is caught by the catcher. The model is trained on 8,892 labeled images, which include footage from professional leagues such as MLB and KBO, self-recorded training videos, and amateur games. The images are labeled in the YOLO format into “ball” and “bat” classes. The system mainly consists of three modules such as baseball detection by YOLO12, trajectory determination by centroid-based tracking and Kalman filtering, velocity calculation based on video frame time data and aerodynamics, pose estimation and dynamic prediction of strike zone by YOLOv8-Pose and MoveNet for body posture analysis at the time of pitcher release, which automatically classifies the pitch as “ball” or “strike”. To overcome the limitations of YOLOv3-tiny and YOLOv5s, YOLO12 uses anchor-free head layer, advanced feature pyramid aggregation and mixed precision (AMP) training, which improves the performance in detecting small and fast-moving objects. The proposed model achieves 0.945 mAP@50 and 8.6 FPS real-time inference speed using a single GPU. This technology could be a cost-effective, scalable, and reliable alternative to commercial tracking systems in baseball analytics. Combining biomechanics and visual analysis, it helps with training, performance evaluation, and broadcasting by analyzing statistics such as player speed, spin trajectory, and pitch results.
